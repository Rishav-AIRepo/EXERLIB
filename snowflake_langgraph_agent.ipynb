{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# NL\u2192SQL Conversational Agent with Snowflake Cortex + Snowpark + LangGraph\n", "\n", "This notebook demonstrates how to build an agentic conversational platform that:\n", "- Converts natural language (NL) queries into SQL using Snowflake Cortex LLM\n", "- Validates & executes queries on Snowflake (mocked locally here)\n", "- Summarizes results for insights\n", "- Uses LangGraph for state & memory management"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import os, re, json, requests, sqlparse, pandas as pd\n", "from typing import Dict, Optional\n", "from langgraph.graph import StateGraph, END\n", "from langchain_core.messages import HumanMessage, AIMessage\n", "from langgraph.checkpoint.memory import MemorySaver\n", "\n", "# -------------------------\n", "# CONFIG\n", "# -------------------------\n", "MOCK_MODE = True\n", "SNOWFLAKE_ACCOUNT = os.getenv(\"SNOWFLAKE_ACCOUNT\", \"<YOUR_ACCOUNT>\")\n", "CORTEX_BEARER_TOKEN = os.getenv(\"CORTEX_BEARER_TOKEN\", \"<YOUR_CORTEX_BEARER_TOKEN>\")\n", "\n", "# -------------------------\n", "# MOCK DATA\n", "# -------------------------\n", "mock_orders = pd.DataFrame({\n", "    \"order_id\": [1, 2, 3, 4, 5],\n", "    \"customer_id\": [10, 11, 10, 12, 13],\n", "    \"order_date\": pd.to_datetime([\"2024-09-01\",\"2024-08-15\",\"2024-07-20\",\"2024-06-05\",\"2024-05-30\"]),\n", "    \"amount\": [120.5, 45.0, 78.9, 150.0, 23.4]\n", "})"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Cortex / Mock LLM\n", "def cortex_infer_rest(prompt: str, model: str = \"mistral-large2\") -> dict:\n", "    url = f\"https://{SNOWFLAKE_ACCOUNT}.snowflakecomputing.com/api/v2/cortex/inference:complete\"\n", "    headers = {\"Authorization\": f\"Bearer {CORTEX_BEARER_TOKEN}\", \"Content-Type\": \"application/json\"}\n", "    payload = {\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n", "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n", "    resp.raise_for_status()\n", "    return resp.json()\n", "\n", "def mock_llm_generate(prompt: str) -> dict:\n", "    sql = \"\"\"\n", "    SELECT DATE_TRUNC('month', order_date) AS year_month,\n", "           SUM(amount) AS total_revenue\n", "    FROM ORDERS\n", "    WHERE order_date >= DATEADD(month, -12, CURRENT_DATE())\n", "    GROUP BY 1\n", "    ORDER BY 1 DESC\n", "    LIMIT 1000\n", "    \"\"\"\n", "    return {\"choices\": [{\"message\": {\"content\": json.dumps({\"sql\": sql})}}]}"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# SQL Validator\n", "def validate_sql(sql_text: str) -> str:\n", "    if \";\" in sql_text:\n", "        raise ValueError(\"Semicolons not allowed\")\n", "    if not sql_text.lower().startswith(\"select\"):\n", "        raise ValueError(\"Only SELECT allowed\")\n", "    if \"limit\" not in sql_text.lower():\n", "        sql_text += \" LIMIT 1000\"\n", "    return sqlparse.format(sql_text, reindent=True, keyword_case=\"upper\")"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# SQL Executor\n", "def execute_sql(sql_text: str) -> pd.DataFrame:\n", "    if MOCK_MODE:\n", "        df = mock_orders.copy()\n", "        df[\"year_month\"] = df[\"order_date\"].dt.to_period(\"M\").astype(str)\n", "        agg = df.groupby(\"year_month\", as_index=False)[\"amount\"].sum()\n", "        agg.rename(columns={\"amount\": \"total_revenue\"}, inplace=True)\n", "        return agg.sort_values(\"year_month\", ascending=False)\n", "    else:\n", "        # session.sql(sql_text).to_pandas()\n", "        raise NotImplementedError(\"Snowflake execution not wired here.\")"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Summarizer\n", "def summarize(df: pd.DataFrame) -> str:\n", "    if \"total_revenue\" in df.columns:\n", "        return f\"Rows: {len(df)} | Max Revenue: {df['total_revenue'].max()} | Avg Revenue: {df['total_revenue'].mean():.2f}\"\n", "    return f\"Rows returned: {len(df)}\""]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Graph State\n", "class AgentState(dict):\n", "    query: str\n", "    sql: Optional[str]\n", "    result: Optional[pd.DataFrame]\n", "    summary: Optional[str]\n", "    messages: list"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# LangGraph Nodes\n", "def llm_node(state: AgentState) -> AgentState:\n", "    schema = \"ORDERS(order_id, customer_id, order_date, amount)\"\n", "    prompt = f\"You are a Snowflake SQL generator. Only return JSON: {{\\\"sql\\\":\\\"<SQL>\\\"}}. Use {schema}. Task: {state['query']}\"\n", "    resp = mock_llm_generate(prompt) if MOCK_MODE else cortex_infer_rest(prompt)\n", "    content = resp[\"choices\"][0][\"message\"][\"content\"]\n", "    try:\n", "        sql = json.loads(content)[\"sql\"]\n", "    except Exception:\n", "        sql = content\n", "    state[\"sql\"] = sql\n", "    state[\"messages\"].append(AIMessage(content=f\"Generated SQL: {sql}\"))\n", "    return state\n", "\n", "def validate_node(state: AgentState) -> AgentState:\n", "    state[\"sql\"] = validate_sql(state[\"sql\"])\n", "    state[\"messages\"].append(AIMessage(content=f\"Validated SQL: {state['sql']}\"))\n", "    return state\n", "\n", "def execute_node(state: AgentState) -> AgentState:\n", "    df = execute_sql(state[\"sql\"])\n", "    state[\"result\"] = df\n", "    state[\"messages\"].append(AIMessage(content=f\"Executed SQL, got {len(df)} rows\"))\n", "    return state\n", "\n", "def summarize_node(state: AgentState) -> AgentState:\n", "    state[\"summary\"] = summarize(state[\"result\"])\n", "    state[\"messages\"].append(AIMessage(content=f\"Summary: {state['summary']}\"))\n", "    return state"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# Build Graph\n", "workflow = StateGraph(AgentState)\n", "workflow.add_node(\"llm\", llm_node)\n", "workflow.add_node(\"validate\", validate_node)\n", "workflow.add_node(\"execute\", execute_node)\n", "workflow.add_node(\"summarize\", summarize_node)\n", "\n", "workflow.set_entry_point(\"llm\")\n", "workflow.add_edge(\"llm\", \"validate\")\n", "workflow.add_edge(\"validate\", \"execute\")\n", "workflow.add_edge(\"execute\", \"summarize\")\n", "workflow.add_edge(\"summarize\", END)\n", "\n", "memory = MemorySaver()\n", "app = workflow.compile(checkpointer=memory)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# Run Conversation\n", "init_state = AgentState(query=\"Show monthly revenue for last 12 months\", sql=None, result=None, summary=None, messages=[HumanMessage(content=\"Show monthly revenue\")])\n", "result = app.invoke(init_state)\n", "\n", "print(\"---- Conversation ----\")\n", "for msg in result[\"messages\"]:\n", "    role = \"USER\" if isinstance(msg, HumanMessage) else \"AGENT\"\n", "    print(f\"{role}: {msg.content}\")\n", "print(\"\\nFinal Summary:\", result[\"summary\"])\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}